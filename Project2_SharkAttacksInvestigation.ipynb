{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c25cd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01: Date;Year;Type;Country;State;Location;Activity;Name;Sex;Age;Injury;Fatal Y/N;Time;Species ;Source;pdf;href formula;href;Case Number;Case Number;original order;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "02: 11th October;2025;Unprovoked;Australia;Queensland;Cook Esplanade Thursday Island;Fishing/swimming;Samuel Nai;M;14;Serious abdonminal injuries;N;1823 hrs;Tiger or Bull shark;Kevin McMurray Trackingsharks.com;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "03: 7th October;2025;Unprovoked;Australia;South Australia;Kangaroo Island;Surfing;Lee Berryman;M;50+;Lacerations to calf ;N;1330hrs;Bronze whaler?;Kevin McMurray Trackingsharks.com;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "04: 29th September;2025;Unprovoked;USA;Off California;Catalina Island;Swimming;Christopher Murray;M;54;Leg and foot injury;N;0100hrs;unknown 1.2m shark;Todd Smith: Kevin McMurray Trackingsharks.com;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "05: 27th September;2025;Provoked;Costa Rica;;Cocos Islands;Diving-Tagging sharks;Dr. Mauricio Hoyos;M;48;Head face and arms;N;Not stated;Tiger shark 4m;Todd Smith: Kevin McMurray Trackingsharks.com;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "06: 6th September;2025;Unprovoked;Australia;NSW;Long Reef Sydney;Surfing;Mercury Psillaskis;M;57;Both legs and arm severed;Y;0930hrs;Great White Shark;Todd Smith: Andy Currie: Simon De Marchi: Kevin McMurray Trackingsharks.com:;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "07: 1st September;2025;Unprovoked;USA;Florida;Horseshoe reef Key Largo;Snorkeling;Richard Burrows;M;8;Bite to leg;N;1524hrs;Not stated;Todd Smith: US SUN: NY Post: The Guardian: People:;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "08: 30th August;2025;Unprovoked;USA;Texas;Galveston;Swimming;Harper Ochoa;F;8;Bite to leg;N;Not stated;Not stated;Bob Myatt GSAF : People:;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "09: 18th August;2025;Unprovoked;Australia;NSW;Cabarita Beach;Surfing;Brad Ross;M;?;None sustained board severly damaged;N;0730hrs;5m (16.5ft) Great White;Bob Myatt GSAF The Guardian: 9 News: ABS News: Daily Telegraph:;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "10: 17th August;2025;Unprovoked;Bahamas;Atlantic Ocean near Big Grand Cay;North of Grand Bahama near Freeport;Spearfishing;Not stated;M;63;Severe injuries no detail;N;1300hrs;Undetermined;Ralph Collier GSAF and Kevin MCMurray Trackingsharks.com ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Script para descargar un archivo de Google Drive y mostrar las primeras 10 líneas\n",
    "'''\n",
    "\n",
    "url_view = \"https://drive.google.com/file/d/1RMKdCJKS7vFBhiTLosCotau1k4UsN5iu/view?usp=sharing\"   # Enlace de Google Drive\n",
    "file_id = url_view.split('/')[5]  # Extrae el ID del archivo (la 6ª parte del enlace)\n",
    "download_url = f\"https://drive.google.com/uc?id={file_id}\"   # Crea el enlace de descarga directa\n",
    "\n",
    "import requests\n",
    "response = requests.get(download_url)\n",
    "\n",
    "# Muestra las primeras 10 líneas, para saber el tipo de separación del csv\n",
    "for i, line in enumerate(response.text.splitlines()[:10], start=1):\n",
    "    print(f\"{i:02d}: {line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ef8877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicialmente los datos tienen: (39139, 255)\n",
      "             Date  Year        Type     Country            State  \\\n",
      "0    11th October  2025  Unprovoked   Australia       Queensland   \n",
      "1     7th October  2025  Unprovoked   Australia  South Australia   \n",
      "2  29th September  2025  Unprovoked         USA   Off California   \n",
      "3  27th September  2025    Provoked  Costa Rica              NaN   \n",
      "4   6th September  2025  Unprovoked   Australia              NSW   \n",
      "\n",
      "                         Location               Activity                Name  \\\n",
      "0  Cook Esplanade Thursday Island       Fishing/swimming          Samuel Nai   \n",
      "1                 Kangaroo Island                Surfing        Lee Berryman   \n",
      "2                 Catalina Island               Swimming  Christopher Murray   \n",
      "3                   Cocos Islands  Diving-Tagging sharks  Dr. Mauricio Hoyos   \n",
      "4                Long Reef Sydney                Surfing  Mercury Psillaskis   \n",
      "\n",
      "  Sex  Age  ... Unnamed: 245 Unnamed: 246 Unnamed: 247 Unnamed: 248  \\\n",
      "0   M   14  ...          NaN          NaN          NaN          NaN   \n",
      "1   M  50+  ...          NaN          NaN          NaN          NaN   \n",
      "2   M   54  ...          NaN          NaN          NaN          NaN   \n",
      "3   M   48  ...          NaN          NaN          NaN          NaN   \n",
      "4   M   57  ...          NaN          NaN          NaN          NaN   \n",
      "\n",
      "  Unnamed: 249 Unnamed: 250 Unnamed: 251 Unnamed: 252 Unnamed: 253  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "  Unnamed: 254  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "[5 rows x 255 columns]\n",
      "Ahora los datos tienen: (39139, 23)\n",
      "Index(['Date', 'Year', 'Type', 'Country', 'State', 'Location', 'Activity',\n",
      "       'Name', 'Sex', 'Age', 'Injury', 'Fatal Y/N', 'Time', 'Species ',\n",
      "       'Source', 'pdf', 'href formula', 'href', 'Case Number', 'Case Number.1',\n",
      "       'original order', 'Unnamed: 21', 'Unnamed: 22'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Optional, Iterable\n",
    "\n",
    "shark_df = pd.read_csv(download_url, sep=';', encoding='utf-8', low_memory=False)\n",
    "print(\"Inicialmente los datos tienen:\", shark_df.shape)\n",
    "print(shark_df.head())  # Muestra las primeras filas del DataFrame\n",
    "\n",
    "shark_df = shark_df.dropna(axis=1, how='all') # Eliminar columnas vacías enteras\n",
    "print(\"Ahora los datos tienen:\",shark_df.shape)\n",
    "print(shark_df.columns)  # Muestra las columnas del DataFrame: 255 col a 23 col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c14c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Type', 'Country', 'State', 'Activity', 'Sex', 'Fatal Y/N',\n",
      "       'Species '],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Quitamos las columnas que no nos sirven para el análisis\n",
    "\n",
    "shark_df.drop(['Date','Location','Name','Age','Injury','Time','Source', 'pdf', 'href formula', 'href', 'Case Number', 'Case Number.1',\n",
    "       'original order', 'Unnamed: 21', 'Unnamed: 22'], axis=1, inplace=True)\n",
    "\n",
    "print(shark_df.columns)  # Muestra las columnas del DataFrame después de eliminar las que no analizaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a0cf08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        type     country            state               activity sex  \\\n",
      "0  2025  unprovoked   australia       queensland       fishing/swimming   m   \n",
      "1  2025  unprovoked   australia  south australia                surfing   m   \n",
      "2  2025  unprovoked         usa   off california               swimming   m   \n",
      "3  2025    provoked  costa rica             <NA>  diving-tagging sharks   m   \n",
      "4  2025  unprovoked   australia              nsw                surfing   m   \n",
      "\n",
      "  fatal_y/n              species  \n",
      "0         n  tiger or bull shark  \n",
      "1         n       bronze whaler?  \n",
      "2         n   unknown 1.2m shark  \n",
      "3         n       tiger shark 4m  \n",
      "4         y    great white shark  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Normalize text columns (strip spaces, set lowercase).\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "df : DataFrame\n",
    "cols : columns to normalize; if None, all object/string columns\n",
    "lower : convert to lowercase\n",
    "strip : strip leading/trailing whitespace\n",
    "normalize_columns: normalize column names (strip, lower, replace spaces with _)\n",
    "\n",
    "Returns\n",
    "-------\n",
    "DataFrame (same object, modified in place style but returns df for chaining)\n",
    "\"\"\"\n",
    "\n",
    "def standardize_text(\n",
    "    df: pd.DataFrame,\n",
    "    cols: Optional[Iterable[str]] = None,\n",
    "    lower: bool = True,\n",
    "    strip: bool = True,\n",
    "    normalize_columns: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "       \n",
    "    if cols is None:\n",
    "        cols = df.select_dtypes(include=[\"object\", \"string\"]).columns\n",
    "\n",
    "    for c in cols:\n",
    "        s = df[c].astype(\"string\")\n",
    "        if strip:\n",
    "            s = s.str.strip()\n",
    "        if lower:\n",
    "            s = s.str.lower()\n",
    "        df[c] = s\n",
    "     \n",
    "    if normalize_columns:\n",
    "        df.columns = (\n",
    "            df.columns\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "            .str.replace(\" \", \"_\")\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "shark_df = standardize_text(shark_df)\n",
    "print(shark_df.head())  # Muestra las primeras filas del DataFrame después de la normalización del texto y las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b631b385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR --> valores únicos: <StringArray>\n",
      "['2025', '2024', '2026', '2023', '2022', '2021', '2020', '2019', '2018',\n",
      " '2017',\n",
      " ...\n",
      " '1580', '1555', '1554', '1543', '1518', '1500', '1000', '0077', '0005',\n",
      " '0000']\n",
      "Length: 263, dtype: string\n",
      "TYPE --> valores únicos: <StringArray>\n",
      "[         'unprovoked',            'provoked',        'questionable',\n",
      "          'watercraft',        'sea disaster',                  <NA>,\n",
      "                   '?',         'unconfirmed',          'unverified',\n",
      "             'invalid', 'under investigation',                'boat']\n",
      "Length: 12, dtype: string\n",
      "COUNTRY --> valores únicos: <StringArray>\n",
      "[               'australia',                      'usa',\n",
      "               'costa rica',                  'bahamas',\n",
      "              'puerto rico',         'french polynesia',\n",
      "                    'spain',           'canary islands',\n",
      "             'south africa',                  'vanuatu',\n",
      " ...\n",
      "        'mediterranean sea',                   'sweden',\n",
      "                   'roatan', 'between portugal & india',\n",
      "                 'djibouti',                  'bahrein',\n",
      "                    'korea',                 'red sea?',\n",
      "                    'asia?',       'ceylon (sri lanka)']\n",
      "Length: 213, dtype: string\n",
      "STATE --> valores únicos: <StringArray>\n",
      "[                       'queensland',                   'south australia',\n",
      "                    'off california',                                <NA>,\n",
      "                               'nsw',                           'florida',\n",
      "                             'texas', 'atlantic ocean near big grand cay',\n",
      "                          'carolina',                         'nuku hiva',\n",
      " ...\n",
      "               'milne bay  province',                   'island of volos',\n",
      "                  'amirante islands',               'kadavu island group',\n",
      "                'toamasina province',                     'riau province',\n",
      "                      'bikini atoll', 'between new ireland & new britain',\n",
      "         'ba ria-vung tau  province',                      'moala island']\n",
      "Length: 909, dtype: string\n",
      "ACTIVITY --> valores únicos: <StringArray>\n",
      "[                                                  'fishing/swimming',\n",
      "                                                            'surfing',\n",
      "                                                           'swimming',\n",
      "                                              'diving-tagging sharks',\n",
      "                                                         'snorkeling',\n",
      "                                                       'spearfishing',\n",
      "                                                            'fishing',\n",
      "                                                             'wading',\n",
      "                                                           'kayaking',\n",
      "                                             'surfing (hydrofoiling)',\n",
      " ...\n",
      " 'standing, washing rear wheels of his ambulance in ankle-deep water',\n",
      "                      'carrying a supposedly dead shark by its mouth',\n",
      "                                             'spent 8 days in dinghy',\n",
      "                       'aircraft ditched in the sea, swimming ashore',\n",
      "                                                'wooden fishing boat',\n",
      "                 'swimming in pool formed by construction of a wharf',\n",
      "                                      'swimming around anchored ship',\n",
      "                        'crew swimming alongside their anchored ship',\n",
      "                                                 '4 men were bathing',\n",
      "                               'wreck of  large double sailing canoe']\n",
      "Length: 1548, dtype: string\n",
      "SEX --> valores únicos: <StringArray>\n",
      "['m', 'f', <NA>, 'lli', 'm x 2', 'n', '.']\n",
      "Length: 7, dtype: string\n",
      "FATAL_Y/N --> valores únicos: <StringArray>\n",
      "['n', 'y', 'f', 'm', <NA>, 'nq', 'unknown', '2017', 'y x 2']\n",
      "Length: 9, dtype: string\n",
      "SPECIES --> valores únicos: <StringArray>\n",
      "[                                                                                                          'tiger or bull shark',\n",
      "                                                                                                                'bronze whaler?',\n",
      "                                                                                                            'unknown 1.2m shark',\n",
      "                                                                                                                'tiger shark 4m',\n",
      "                                                                                                             'great white shark',\n",
      "                                                                                                                    'not stated',\n",
      "                                                                                                       '5m (16.5ft) great white',\n",
      "                                                                                                                  'undetermined',\n",
      "                                                                                                       'lemon shark 1.8 m (6ft)',\n",
      "                                                                                                         'suspected great white',\n",
      " ...\n",
      "                                                                                                      'a large hammerhead shark',\n",
      "                                                                                             'shovelnose guitarfish, adult male',\n",
      "                                                                                                            '\"a pack of sharks\"',\n",
      "                                                                                                         'white shark, 7' to 8'',\n",
      "                                                                                                         'white shark, 1,900-lb',\n",
      "                                                               'bull shark caught, leg recovered & buried beside the man's body',\n",
      "                                                                                                        '\"a black-tipped shark\"',\n",
      "                                                                                                               '12' tiger shark',\n",
      "                                                                                                                 'blue pointers',\n",
      " 'said to involve a grey nurse shark that leapt out of the water and  seized the boy but species identification is questionable']\n",
      "Length: 1613, dtype: string\n"
     ]
    }
   ],
   "source": [
    "#Check valores únicos por columna:\n",
    "\n",
    "for col in shark_df.columns:\n",
    "    print(f'{col.upper()} --> valores únicos:', shark_df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91990ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year         string[python]\n",
       "type         string[python]\n",
       "country      string[python]\n",
       "state        string[python]\n",
       "activity     string[python]\n",
       "sex          string[python]\n",
       "fatal_y/n    string[python]\n",
       "species      string[python]\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shark_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365618c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los valores iniciales eran: <bound method IndexOpsMixin.nunique of 0        2025\n",
      "1        2025\n",
      "2        2025\n",
      "3        2025\n",
      "4        2025\n",
      "         ... \n",
      "39134    <NA>\n",
      "39135    <NA>\n",
      "39136    <NA>\n",
      "39137    <NA>\n",
      "39138    <NA>\n",
      "Name: year, Length: 39139, dtype: string>\n",
      "Los valores iniciales eran: (39139,)\n",
      "Los valores iniciales eran: <bound method IndexOpsMixin.nunique of 0        unprovoked\n",
      "1        unprovoked\n",
      "2        unprovoked\n",
      "3          provoked\n",
      "4        unprovoked\n",
      "            ...    \n",
      "39134          <NA>\n",
      "39135          <NA>\n",
      "39136          <NA>\n",
      "39137          <NA>\n",
      "39138          <NA>\n",
      "Name: type, Length: 39139, dtype: string>\n",
      "Los valores iniciales eran: (39139,)\n"
     ]
    }
   ],
   "source": [
    "print('Los valores iniciales eran:', shark_df['year'].nunique)\n",
    "print('Los valores iniciales eran:', shark_df['year'].shape)\n",
    "print('Los valores iniciales eran:', shark_df['type'].nunique)\n",
    "print('Los valores iniciales eran:', shark_df['type'].shape)\n",
    "\n",
    "#PRIMER FILTRO (Marlene):\n",
    "\n",
    "shark_df = shark_df[shark_df['type'] == 'unprovoked'].copy() #Quitamos los accidentes que no sean \"unprovoked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ae12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos a excel post filtro: TYPE\n",
    "\n",
    "shark_df.to_excel('SharkAttack_check1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ac7041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year    1\n",
      "dtype: int64\n",
      "year            0\n",
      "type            0\n",
      "country        33\n",
      "state         300\n",
      "activity      359\n",
      "sex           168\n",
      "fatal_y/n      17\n",
      "species      2598\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(shark_df[['year']].isnull().sum())\n",
    "\n",
    "shark_df = shark_df.dropna(subset=['year']) #Quitamos los null de la columna \"year\"\n",
    "\n",
    "print(shark_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e5ae0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post filtro quedan: (2206,) valores\n",
      "Post filtro quedan: (2206,) valores\n"
     ]
    }
   ],
   "source": [
    "#formateamos para que todos los string sean igual (con decimal \".\")\n",
    "\n",
    "shark_df['year'] = (\n",
    "    shark_df['year']\n",
    "    .astype(str)                 \n",
    "    .str.replace(',', '.', regex=False)  # cambia coma por punto\n",
    "    .astype(float)      \n",
    ")\n",
    "shark_df['year'] = pd.to_numeric(shark_df['year'])\n",
    "shark_df = shark_df.loc[(shark_df['year'] >= 2000) & (shark_df['year'] <= 2025)] #filtramos los años sujetos a estudio\n",
    "\n",
    "#CHECK FILTRO 1\n",
    "print('Post filtro quedan:', shark_df['year'].shape , \"valores\")\n",
    "print('Post filtro quedan:', shark_df['type'].shape , \"valores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40e7d16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR --> valores únicos: [2025. 2024. 2023. 2022. 2021. 2020. 2019. 2018. 2017. 2016. 2015. 2014.\n",
      " 2013. 2012. 2011. 2010. 2009. 2008. 2007. 2006. 2005. 2004. 2003. 2002.\n",
      " 2001. 2000.]\n",
      "TYPE --> valores únicos: <StringArray>\n",
      "['unprovoked']\n",
      "Length: 1, dtype: string\n",
      "COUNTRY --> valores únicos: <StringArray>\n",
      "[                            'australia',\n",
      "                                   'usa',\n",
      "                               'bahamas',\n",
      "                           'puerto rico',\n",
      "                      'french polynesia',\n",
      "                                 'spain',\n",
      "                        'canary islands',\n",
      "                          'south africa',\n",
      "                               'vanuatu',\n",
      "                               'jamaica',\n",
      "                                'israel',\n",
      "                              'maldives',\n",
      "                      'turks and caicos',\n",
      "                            'mozambique',\n",
      "                         'new caledonia',\n",
      "                                 'egypt',\n",
      "                              'thailand',\n",
      "                           'new zealand',\n",
      "                                'hawaii',\n",
      "                              'honduras',\n",
      "                               'morocco',\n",
      "                                'belize',\n",
      "                       'maldive islands',\n",
      "                                'tobago',\n",
      "                                 'india',\n",
      "                                'mexico',\n",
      "                           'philippines',\n",
      "                                 'samoa',\n",
      "                              'colombia',\n",
      "                               'ecuador',\n",
      "                                'brazil',\n",
      "                            'seychelles',\n",
      "                               'england',\n",
      "                                 'japan',\n",
      "                             'indonesia',\n",
      "                              'columbia',\n",
      "            'british overseas territory',\n",
      "                                'canada',\n",
      "                                'jordan',\n",
      "                      'st kitts / nevis',\n",
      "                             'st martin',\n",
      "                                  'fiji',\n",
      "                      'papua new guinea',\n",
      "                                  'cuba',\n",
      "                        'reunion island',\n",
      "                                 'italy',\n",
      "                            'costa rica',\n",
      "                                    <NA>,\n",
      "                             'mauritius',\n",
      "                       'solomon islands',\n",
      " 'st helena, british overseas territory',\n",
      "                               'reunion',\n",
      "                        'united kingdom',\n",
      "                  'united arab emirates',\n",
      "                                 'china',\n",
      "                    'dominican republic',\n",
      "                                 'aruba',\n",
      "                                'france',\n",
      "                              'kiribati',\n",
      "                          'diego garcia',\n",
      "                                'taiwan',\n",
      "                                  'guam',\n",
      "                               'nigeria',\n",
      "                                 'tonga',\n",
      "                              'scotland',\n",
      "                                 'kenya',\n",
      "                                'russia',\n",
      "                        'turks & caicos',\n",
      "                              'malaysia',\n",
      "                           'south korea',\n",
      "                                 'malta',\n",
      "                               'vietnam',\n",
      "                            'madagascar',\n",
      "            'united arab emirates (uae)',\n",
      "                                'panama',\n",
      "                               'croatia',\n",
      "                                 'yemen',\n",
      "                          'gulf of aden',\n",
      "                          'sierra leone',\n",
      "                           'st. maartin',\n",
      "                          'grand cayman',\n",
      "                             'venezuela',\n",
      "                               'uruguay',\n",
      "                            'micronesia',\n",
      "                               'okinawa',\n",
      "                              'tanzania']\n",
      "Length: 86, dtype: string\n",
      "STATE --> valores únicos: <StringArray>\n",
      "[                                         'queensland',\n",
      "                                     'south australia',\n",
      "                                      'off california',\n",
      "                                                 'nsw',\n",
      "                                             'florida',\n",
      "                                               'texas',\n",
      "                   'atlantic ocean near big grand cay',\n",
      "                                            'carolina',\n",
      "                                           'nuku hiva',\n",
      "                                             'majorca',\n",
      " ...\n",
      "                               'louisiade archipelago',\n",
      " 'kwazulu-natal between port edward and port st johns',\n",
      "                                  'milne bay province',\n",
      "                'cikobia island (north of vanua levu)',\n",
      "                                     'rayong province',\n",
      "                                 'rio grande de norte',\n",
      "                                       'new brunswick',\n",
      "                                       'miyako island',\n",
      "                                        'minerva reef',\n",
      "                                     'madang province']\n",
      "Length: 294, dtype: string\n",
      "ACTIVITY --> valores únicos: <StringArray>\n",
      "[                                'fishing/swimming',\n",
      "                                          'surfing',\n",
      "                                         'swimming',\n",
      "                                       'snorkeling',\n",
      "                                     'spearfishing',\n",
      "                                           'wading',\n",
      "                                         'kayaking',\n",
      "                           'surfing (hydrofoiling)',\n",
      "                                           'diving',\n",
      "                                          'fishing',\n",
      " ...\n",
      "                     'standing alongside surfboard',\n",
      "                                            'batin',\n",
      "             'swimming back from anchored sailboat',\n",
      "                           'diving for sea urchins',\n",
      "                       'diving (shell maintenance)',\n",
      "                        'swimming out to porpoises',\n",
      "            'windsurfing, but sitting on his board',\n",
      "                                 'surfing / wading',\n",
      " 'spearfishing, holding mesh bag with speared fish',\n",
      "                         'boogie boarding / wading']\n",
      "Length: 233, dtype: string\n",
      "SEX --> valores únicos: <StringArray>\n",
      "['m', 'f', <NA>, 'lli']\n",
      "Length: 4, dtype: string\n",
      "FATAL_Y/N --> valores únicos: <StringArray>\n",
      "['n', 'y', 'f', 'm', <NA>, 'nq', 'unknown']\n",
      "Length: 7, dtype: string\n",
      "SPECIES --> valores únicos: <StringArray>\n",
      "[                                    'tiger or bull shark',\n",
      "                                          'bronze whaler?',\n",
      "                                      'unknown 1.2m shark',\n",
      "                                       'great white shark',\n",
      "                                              'not stated',\n",
      "                                 '5m (16.5ft) great white',\n",
      "                                            'undetermined',\n",
      "                                   'suspected great white',\n",
      "                         'great white shark est 3m (10ft)',\n",
      "                                             'lemon shark',\n",
      " ...\n",
      "                'blacktip shark, 2.4 m to 3 m [8' to 10']',\n",
      "                           '1.8 m [6'] grey-colored shark',\n",
      "                            'grey reef shark, 2 m [6.75']',\n",
      "                 'lemon shark, 2.1  m to 2.4 m [7' to 8']',\n",
      "                'tiger shark, 0.9 m to 1.5 m [3' to 5'] ?',\n",
      "                                 'nurse shark, 1.2 m [4']',\n",
      " '0.9 m [3'] shark,  probably a blacktip or spinner shark',\n",
      "               'blacktip shark, 1.2 m to 1.8 m [4' to 6']',\n",
      "                                'tiger shark, 4 m [13'] ?',\n",
      "          'shortfin mako shark, 3 m to 3.4 m [10' to 11']']\n",
      "Length: 625, dtype: string\n"
     ]
    }
   ],
   "source": [
    "#Check valores por columnas para próximos filtros\n",
    "\n",
    "for col in shark_df.columns:\n",
    "    print(f'{col.upper()} --> valores únicos:', shark_df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08ccfc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos a excel post filtro: TYPE + YEAR\n",
    "\n",
    "shark_df.to_excel('SharkAttack_check2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14c3181a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después del segundo filtro, los datos tienen: (1977, 8)\n",
      "country\n",
      "australia            434\n",
      "bahamas               69\n",
      "brazil                54\n",
      "egypt                 30\n",
      "french polynesia      26\n",
      "mexico                25\n",
      "new caledonia         35\n",
      "new zealand           38\n",
      "reunion               30\n",
      "south africa         115\n",
      "usa                 1121\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#SEGUNDO FILTRO (Marta):\n",
    "#Decidimos filtrar por 11 países que representan el 90% de los ataques. \n",
    "country_selected = [\n",
    "    \"usa\",\"australia\",\"south africa\",\"bahamas\",\"brazil\",\"new zealand\",\n",
    "    \"new caledonia\",\"egypt\",\"reunion\",\"french polynesia\",\"mexico\",\"reunion island\"]\n",
    "\n",
    "shark_df_filtered = shark_df[\n",
    "    shark_df[\"country\"].str.strip().str.lower().isin(country_selected)\n",
    "].copy()\n",
    "\n",
    "print(\"Después del segundo filtro, los datos tienen:\", shark_df_filtered.shape)\n",
    "# Reunion y Reunion island los llamamos como Reunion Island\n",
    "\n",
    "map_reunion = {\"reunion island\": \"reunion\"}\n",
    "shark_df_filtered[\"country\"] = shark_df_filtered[\"country\"].replace(map_reunion)\n",
    "print(shark_df_filtered[\"country\"].value_counts(dropna=False).sort_index())\n",
    "shark_df = shark_df_filtered #sobrescribe el dataframe con los filtros y demás\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c18bb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes: (1977, 8)\n",
      "Después: (1934, 8)\n"
     ]
    }
   ],
   "source": [
    "# Borramos state en blanco para esos paises\n",
    "print(\"Antes:\", shark_df_filtered.shape)\n",
    "shark_df_filtered = shark_df_filtered.dropna(subset=[\"state\"]).copy()\n",
    "print(\"Después:\", shark_df_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd33491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de normalizar estados USA: state\n",
      "florida              602\n",
      "hawaii               152\n",
      "california           103\n",
      "south carolina        79\n",
      "north carolina        69\n",
      "texas                 34\n",
      "new york              16\n",
      "oregon                16\n",
      "alabama               10\n",
      "louisiana              6\n",
      "georgia                5\n",
      "new jersey             5\n",
      "massachusetts          4\n",
      "maine                  2\n",
      "guam                   2\n",
      "us virgin islands      2\n",
      "virginia               2\n",
      "galveston              1\n",
      "samoa                  1\n",
      "maryland               1\n",
      "cayman islands         1\n",
      "bahamas                1\n",
      "washington             1\n",
      "rhode island           1\n",
      "delaware               1\n",
      "palmyra atoll          1\n",
      "puerto rico            1\n",
      "johnston atoll         1\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#Normalizando nombres de estados para los países seleccionados\n",
    "#USA:\n",
    "\n",
    "mask_usa = shark_df_filtered[\"country\"].eq(\"usa\")\n",
    "\n",
    "# Diccionario de normalización (todo en minúsculas)\n",
    "usa_state_map = {\n",
    "    \"floria\": \"florida\",\n",
    "    \"franklin county, florida\": \"florida\",\n",
    "    \"noirth carolina\": \"north carolina\",\n",
    "    \"off california\": \"california\",\n",
    "    \"los angeles\": \"california\",\n",
    "    \"long island ny\": \"new york\",\n",
    "    \"maui\": \"hawaii\",\n",
    "    \"virgin islands\": \"us virgin islands\",\n",
    " }\n",
    "\n",
    "print(\"Después de normalizar estados USA:\", shark_df_filtered.loc[mask_usa, \"state\"].replace(usa_state_map).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f015f506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de normalizar estados AU: state\n",
      "new south wales                         164\n",
      "western australia                       120\n",
      "queensland                               77\n",
      "south australia                          36\n",
      "victoria                                 23\n",
      "tasmania                                  6\n",
      "northern territory                        5\n",
      "torres strait                             1\n",
      "territory of cocos (keeling) islands      1\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#Australia:\n",
    "\n",
    "mask_aus = shark_df_filtered[\"country\"].eq(\"australia\")\n",
    "\n",
    "aus_state_map = {\n",
    "    \"new  south wales\": \"new south wales\",\n",
    "    \"new south ales\": \"new south wales\",\n",
    "    \"nsw\": \"new south wales\",\n",
    "    \"wa\": \"western australia\",\n",
    "    \"westerm australia\": \"western australia\",\n",
    "    \"western  australia\": \"western australia\",\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"Después de normalizar estados AU:\",\n",
    "    shark_df_filtered.loc[mask_aus, \"state\"]\n",
    "        .replace(aus_state_map)\n",
    "        .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b25a7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de normalizar estados South Africa: state\n",
      "western cape     48\n",
      "eastern cape     46\n",
      "kwazulu-natal    19\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#South Africa:\n",
    "mask_sa = shark_df_filtered[\"country\"].eq(\"south africa\")\n",
    "\n",
    "sa_state_map = {\n",
    "    \"easten cape province\": \"eastern cape\",\n",
    "    \"eastern cape  province\": \"eastern cape\",\n",
    "    \"eastern cape province\": \"eastern cape\",\n",
    "    \"eastern province\": \"eastern cape\", \n",
    "    \"kwazulu-natal between port edward and port st johns\": \"kwazulu-natal\",\n",
    "    \"western cape province\": \"western cape\",\n",
    "    \"western province\": \"western cape\",\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"Después de normalizar estados South Africa:\",\n",
    "    shark_df_filtered.loc[mask_sa, \"state\"]\n",
    "        .replace(sa_state_map)\n",
    "        .value_counts()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57812515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de normalizar Bahamas: state\n",
      "abaco                  22\n",
      "grand bahama           10\n",
      "exuma                   7\n",
      "new providence          7\n",
      "eleuthera               2\n",
      "long island             1\n",
      "lucayan archipelago     1\n",
      "bimini                  1\n",
      "northern bahamas        1\n",
      "andros                  1\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#Bahamas:\n",
    "mask_bhs = shark_df_filtered[\"country\"].eq(\"bahamas\")\n",
    "\n",
    "bahamas_state_map = {\n",
    "    # --- Grand Bahama (incluye off-shore y ciudades) ---\n",
    "    \"40 miles off grand bahama island\": \"grand bahama\",\n",
    "    \"grand  bahama island\": \"grand bahama\",\n",
    "    \"grand bahama island\": \"grand bahama\",\n",
    "    \"freeport\": \"grand bahama\",\n",
    "    \"west end\": \"grand bahama\",\n",
    "\n",
    "    # --- Abaco ---\n",
    "    \"abaco islands\": \"abaco\",\n",
    "    \"great abaco islands\": \"abaco\",\n",
    "    \"atlantic ocean near big grand cay\": \"abaco\",\n",
    "\n",
    "    # --- Andros ---\n",
    "    \"andros islands\": \"andros\",\n",
    "\n",
    "    # --- Exuma ---\n",
    "    \"exuma islands\": \"exuma\",\n",
    "    \"exumas\": \"exuma\",\n",
    "    \"the exuma cays\": \"exuma\",\n",
    "\n",
    "    # --- New Providence (+ Paradise Island y variantes tipográficas) ---\n",
    "    \"new providence   isoad\": \"new providence\",\n",
    "    \"new providence district\": \"new providence\",\n",
    "    \"new providence island\": \"new providence\",\n",
    "    \"paradise island\": \"new providence\",\n",
    "\n",
    "    # --- Long Island (typo en el dato) ---\n",
    "    \"clarence town long isand\": \"long island\",\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"Después de normalizar Bahamas:\",\n",
    "    shark_df_filtered.loc[mask_bhs, \"state\"]\n",
    "        .str.strip().str.lower()\n",
    "        .replace(bahamas_state_map)\n",
    "        .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d430eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de normalizar Brasil: state\n",
      "pernambuco             42\n",
      "sao paulo               2\n",
      "santa catarina          2\n",
      "bahia                   2\n",
      "rio de janeiro          2\n",
      "rio grande do sul       1\n",
      "rio grande do norte     1\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#Brasil:\n",
    "mask_bra = shark_df_filtered[\"country\"].eq(\"brazil\")\n",
    "\n",
    "brazil_state_map = {\n",
    "    \"balneário camboriú\": \"santa catarina\",\n",
    "    \"santa catarina state\": \"santa catarina\",\n",
    "    \"rio grande de norte\": \"rio grande do norte\",\n",
    "    \"fernando de noronha\": \"pernambuco\",\n",
    "    \"são paulo.\": \"sao paulo\",\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"Después de normalizar Brasil:\",\n",
    "    shark_df_filtered.loc[mask_bra, \"state\"]\n",
    "        .str.strip().str.lower()\n",
    "        .replace(brazil_state_map)\n",
    "        .value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a31f85f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de normalizar New Zealand: state\n",
      "south island       18\n",
      "north island       16\n",
      "cook islands        3\n",
      "chatham islands     1\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#New Zealand:\n",
    "mask_nz = shark_df_filtered[\"country\"].eq(\"new zealand\")\n",
    "\n",
    "nz_state_map = {\n",
    "    \"south island, near karitane north of dunedin\": \"south island\",\n",
    "    \"southland\": \"south island\",\n",
    "    \"bay of waitangi\": \"north island\",\n",
    "    \"mercury islands\": \"north island\",\n",
    "  }\n",
    "\n",
    "print(\n",
    "    \"Después de normalizar New Zealand:\",\n",
    "    shark_df_filtered.loc[mask_nz, \"state\"]\n",
    "        .str.strip().str.lower()\n",
    "        .replace(nz_state_map)\n",
    "        .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07ea57ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de normalizar New Caledonia: state\n",
      "south province          8\n",
      "north province          8\n",
      "loyalty islands         5\n",
      "grand terre             2\n",
      "poum                    1\n",
      "belep islands           1\n",
      "noumea                  1\n",
      "baie de sainte-marie    1\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#New Caledonia:\n",
    "\n",
    "mask_nc = shark_df_filtered[\"country\"].eq(\"new caledonia\")\n",
    "\n",
    "nc_state_map = {\n",
    "    \"bélep islands\": \"belep islands\",\n",
    "    \"grande terre\": \"grand terre\",\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"Después de normalizar New Caledonia:\",\n",
    "    shark_df_filtered.loc[mask_nc, \"state\"]\n",
    "        .str.strip().str.lower()\n",
    "        .replace(nc_state_map)\n",
    "        .value_counts()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6532511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de normalizar Egipto: state\n",
      "red sea governorate    12\n",
      "south sinai            12\n",
      "suez                    1\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#Egipto:\n",
    "mask_egy = shark_df_filtered[\"country\"].eq(\"egypt\")\n",
    "\n",
    "egypt_state_map = {\n",
    "    \"hurghada, red sea governorate\": \"red sea governorate\",\n",
    "    \"north of marsa alam\": \"red sea governorate\",\n",
    "    \"red sea\": \"red sea governorate\",\n",
    "    \"red sea protectorate\": \"red sea governorate\",\n",
    "    \"st. johns reef\": \"red sea governorate\",\n",
    "    \"sinai peninsula\": \"south sinai\",\n",
    "    \"south sinai peninsula\": \"south sinai\",\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"Después de normalizar Egipto:\",\n",
    "    shark_df_filtered.loc[mask_egy, \"state\"]\n",
    "        .str.strip().str.lower()\n",
    "        .replace(egypt_state_map)\n",
    "        .value_counts()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "564fb65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de normalizar Reunion:\n",
      "state\n",
      "saint areas               17\n",
      "d’étang salé               2\n",
      "le port                    1\n",
      "trois bassins              1\n",
      "bois blanc                 1\n",
      "conservatoria district     1\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#Reunion:\n",
    "\n",
    "mask_reu = shark_df_filtered[\"country\"].eq(\"reunion\")\n",
    "\n",
    "s = (\n",
    "    shark_df_filtered.loc[mask_reu, \"state\"]\n",
    "        .astype(\"string\")\n",
    "        .str.strip().str.lower()\n",
    "        .str.replace(\"-\", \" \", regex=False)         # \"saint-gilles\" -> \"saint gilles\"\n",
    "        .replace({\n",
    "            \"saint guilles\": \"saint gilles\",        # typo\n",
    "            \"saint gilles les bains\": \"saint gilles\",\n",
    "            \"d'etang-sale\": \"etang sale\",\n",
    "            \"d’etang-sale\": \"etang sale\",\n",
    "            \"d'etang-salé\": \"etang sale\",\n",
    "            \"d’etang-salé\": \"etang sale\",\n",
    "            \"conservatória district\": \"conservatoria district\",\n",
    "        })\n",
    ")\n",
    "\n",
    "# Agrupa TODO lo que empiece por \"saint \" en \"saint areas\"\n",
    "s = s.where(~s.str.startswith(\"saint \"), \"saint areas\")\n",
    "\n",
    "print(\"Después de normalizar Reunion:\")\n",
    "print(s.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a96d050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de normalizar French Polynesia: state\n",
      "society islands    14\n",
      "tuamotu islands     6\n",
      "marquesas           4\n",
      "gambier islands     1\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# French Polynesia\n",
    "mask_fp = shark_df_filtered[\"country\"].eq(\"french polynesia\")\n",
    "\n",
    "french_poly_map = {\n",
    "    # Society Islands\n",
    "    \"bora bora\": \"society islands\",\n",
    "    \"moorea\": \"society islands\",\n",
    "    \"tahiti\": \"society islands\",\n",
    "    \"nuku hiva\": \"marquesas\",\n",
    "    \"central tuamotu\": \"tuamotu islands\",\n",
    "    \"tuamotos\": \"tuamotu islands\",\n",
    "    \"tuamotus\": \"tuamotu islands\",\n",
    "    \"rangiroa\": \"tuamotu islands\",\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"Después de normalizar French Polynesia:\",\n",
    "    shark_df_filtered.loc[mask_fp, \"state\"]\n",
    "        .str.strip().str.lower()\n",
    "        .replace(french_poly_map)\n",
    "        .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24911fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de normalizar Méxipwdco: state\n",
      "quintana roo          7\n",
      "baja california       6\n",
      "guerrero              6\n",
      "sonora                3\n",
      "jalisco               1\n",
      "gulf of california    1\n",
      "sinaloa               1\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "#Mexico:\n",
    "mask_mex = shark_df_filtered[\"country\"].eq(\"mexico\")\n",
    "\n",
    "mexico_state_map = {\n",
    "    \"guerrero\": \"guerrero\",\n",
    "    \"cabo san lucas\": \"baja california\",\n",
    "    \"baja\": \"baja california\",\n",
    "    \"baja california sur\": \"baja california\",\n",
    "    \"guerro\": \"guerrero\",\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"Después de normalizar Méxipwdco:\",\n",
    "    shark_df_filtered.loc[mask_mex, \"state\"]\n",
    "        .str.strip().str.lower()\n",
    "        .replace(mexico_state_map)\n",
    "        .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae2ba89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos los cambios al dataframe principal\n",
    "# Use shark_df_filtered since the masks were created from it\n",
    "shark_df_filtered.loc[mask_usa, \"state\"] = shark_df_filtered.loc[mask_usa, \"state\"].replace(usa_state_map)\n",
    "shark_df_filtered.loc[mask_aus, \"state\"] = shark_df_filtered.loc[mask_aus, \"state\"].replace(aus_state_map)\n",
    "shark_df_filtered.loc[mask_sa, \"state\"] = shark_df_filtered.loc[mask_sa, \"state\"].replace(sa_state_map)\n",
    "shark_df_filtered.loc[mask_bhs, \"state\"] = shark_df_filtered.loc[mask_bhs, \"state\"].replace(bahamas_state_map)\n",
    "shark_df_filtered.loc[mask_bra, \"state\"] = shark_df_filtered.loc[mask_bra, \"state\"].replace(brazil_state_map)\n",
    "shark_df_filtered.loc[mask_nz, \"state\"] = shark_df_filtered.loc[mask_nz, \"state\"].replace(nz_state_map)\n",
    "shark_df_filtered.loc[mask_nc, \"state\"] = shark_df_filtered.loc[mask_nc, \"state\"].replace(nc_state_map)\n",
    "shark_df_filtered.loc[mask_egy, \"state\"] = shark_df_filtered.loc[mask_egy, \"state\"].replace(egypt_state_map)\n",
    "shark_df_filtered.loc[mask_reu, \"state\"] = s\n",
    "shark_df_filtered.loc[mask_fp, \"state\"] = shark_df_filtered.loc[mask_fp, \"state\"].replace(french_poly_map)\n",
    "shark_df_filtered.loc[mask_mex, \"state\"] = shark_df_filtered.loc[mask_mex, \"state\"].replace(mexico_state_map)\n",
    "shark_df\n",
    "\n",
    "# Update shark_df to the cleaned version\n",
    "shark_df = shark_df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0954468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos a excel post filtro: TYPE + YEAR + COUNTRY + LOCATION\n",
    "\n",
    "shark_df.to_excel('SharkAttack_check3.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
